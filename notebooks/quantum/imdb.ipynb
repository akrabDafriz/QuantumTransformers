{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb Reviews (Quantum)\n",
    "\n",
    "This notebook trains and evaluates a quantum transformer for the IMDb Reviews sentiment classification task. Note that this is a text classification task.\n",
    "You can find information about the dataset at https://www.tensorflow.org/datasets/catalog/imdb_reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T22:23:18.422798Z",
     "iopub.status.busy": "2023-10-09T22:23:18.422674Z",
     "iopub.status.idle": "2023-10-09T22:23:29.124548Z",
     "shell.execute_reply": "2023-10-09T22:23:29.124133Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 10:01:17.976755: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755568880.555112    2408 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755568880.920186    2408 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755568886.159207    2408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755568886.159255    2408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755568886.159257    2408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755568886.159259    2408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "E0000 00:00:1755568994.704093    2408 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1755568994.714592    2408 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Please first ``pip install -U qiskit`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "from quantum_transformers.datasets import get_imdb_dataloaders\n",
    "from quantum_transformers.training import train_and_evaluate\n",
    "from quantum_transformers.transformers import Transformer\n",
    "from quantum_transformers.quantum_layer import get_circuit\n",
    "\n",
    "data_dir = '/global/cfs/cdirs/m4392/salcc/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models are trained using the following devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T22:23:29.126883Z",
     "iopub.status.busy": "2023-10-09T22:23:29.126510Z",
     "iopub.status.idle": "2023-10-09T22:23:29.334752Z",
     "shell.execute_reply": "2023-10-09T22:23:29.334351Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRT_CPU_0 cpu\n"
     ]
    }
   ],
   "source": [
    "for d in jax.devices():\n",
    "    print(d, d.device_kind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how big is the vocabulary, and see an example of one example review (both in tokenized and raw form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T22:23:29.336517Z",
     "iopub.status.busy": "2023-10-09T22:23:29.336376Z",
     "iopub.status.idle": "2023-10-09T22:25:08.033572Z",
     "shell.execute_reply": "2023-10-09T22:25:08.033125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardinalities (train, val, test): 22500 2500 25000\n",
      "Vocabulary size: 19769\n",
      "[  150   905  1336  2244   105    42  1114   369   106   163   106    42\n",
      "  1114  2058    17   191   121    15   146   263   246  3020   142   167\n",
      "    42   224   133   298   102   120   284    15    96   104   105   277\n",
      "   165  2244    10    60 10135 10476   138  1554  4074   575   113   361\n",
      "    17    31   100    18    33    31   100    18    33    50   327   104\n",
      "   106    95  4751    10    60  4788   113    15    95   584    97    95\n",
      "   215    10    60   198   156   742    98  5364    17    95  1230  5861\n",
      "  1342   288   105   256   439    97   358    98  7101   108  2715  1564\n",
      "    10    60  2438 11147   288   153   478   135   122    95   262   148\n",
      "    17   471   149    42   668  1674  3898    15   110   256   156  1034\n",
      "   107  1336   408   225   243    17   117  1047   203   102 12557    15\n",
      "   117   318 12061   135    17    17    17  2244  1582   143   129    42\n",
      " 12230    98    95  3026    10    60    17    95   320   177  2244   111\n",
      "    97   103   893   105   331  2733  2379    10    60  2789   102  9587\n",
      "    17     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "no doubt frank sinatra was a talented actor as well as a talented singer . after all , very few actors nowadays can get a scene just right in one take , and that was pretty much sinatra ' s modus operandi on set . < br / > < br / > i feel that as the 1960 ' s wore on , the quality of the man ' s films really started to tank . the tony rome detective series was nothing short of trying to compete with dean martin ' s matt helm series which came out at the same time . perhaps even a james bond competition , but nothing really worked for frank during these years . his personal life in shambles , his music fading out . . . sinatra appeared more like a throwback to the 1950 ' s . the last great sinatra film of this period was probably von ryan ' s express in 1965 . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters\n",
    "batch_size = 32\n",
    "max_vocab_size = 20_000\n",
    "max_seq_len = 512\n",
    "\n",
    "# Load the data\n",
    "(train_dataloader, val_dataloader, test_dataloader), vocab, tokenizer = get_imdb_dataloaders(\n",
    "    data_dir='./data', \n",
    "    batch_size=batch_size, \n",
    "    max_vocab_size=max_vocab_size, \n",
    "    max_seq_len=max_seq_len\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "first_batch = next(iter(train_dataloader))\n",
    "print(first_batch[0][0])\n",
    "print(' '.join(map(bytes.decode, tokenizer.detokenize(first_batch[0])[0].numpy().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T22:25:08.035283Z",
     "iopub.status.busy": "2023-10-09T22:25:08.035136Z",
     "iopub.status.idle": "2023-10-09T23:00:53.539551Z",
     "shell.execute_reply": "2023-10-09T23:00:53.539071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters = 122096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/1: 100%|██████████| 703/703 [1:06:03<00:00,  5.64s/batch, Loss = 0.6951, AUC = 0.496, Train time = 2901.19s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation AUC = 0.496 at epoch 1\n",
      "Total training time = 2901.19s, total time (including evaluations) = 3915.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 781/781 [18:30<00:00,  1.42s/batch, Loss = 0.6973, AUC = 0.485]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_losses': Array([0.6963565], dtype=float32),\n",
       " 'val_losses': Array([0.6950757], dtype=float32),\n",
       " 'train_aucs': Array([0.4909439], dtype=float32),\n",
       " 'val_aucs': Array([0.49571323], dtype=float32),\n",
       " 'test_loss': Array(0.6972679, dtype=float32),\n",
       " 'test_auc': 0.48519720574853364,\n",
       " 'test_fpr': array([0.00000000e+00, 8.00128020e-05, 5.60089614e-04, ...,\n",
       "        9.99679949e-01, 9.99679949e-01, 1.00000000e+00]),\n",
       " 'test_tpr': array([0.        , 0.        , 0.        , ..., 0.99983992, 1.        ,\n",
       "        1.        ])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=6, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=3,\n",
    "                    quantum_attn_circuit=get_circuit(), quantum_mlp_circuit=get_circuit())\n",
    "train_and_evaluate(model, train_dataloader, val_dataloader, test_dataloader, num_classes=2, num_epochs=1) # change num_epochs as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
